---
title: "Lasting Special Places"
output:
  html_document:
    number_sections: yes
    toc: yes
    toc_float: yes
  github_document:
    pandoc_args: --output=README.md
  html_notebook:
    number_sections: yes
    toc: yes
    toc_float: yes
---


```{r, load packages}
#### load R packages ####
# devtools::install_github("remi-daigle/flickRgeotag")
require(flickRgeotag)
require(sf)
# devtools::install_github("flovv/RoogleVision")
require(RoogleVision)
# devtools::install_github("MarkEdmondson1234/googleAuthR")
require(googleAuthR)
require(tidyverse)
```


```{r, load regions,cache=TRUE}
regions <- read_sf("../Spatial/regions_final.shp") %>% 
  st_simplify(preserveTopology=T,dTolerance=100)

regions3kmbuff <- st_union(st_buffer(regions,dist=3000)) %>% 
  st_simplify(preserveTopology=T,dTolerance=100)

ggplot() +
  geom_sf(data=regions,aes(fill=Name))
```


```{r, load secrets,cache=TRUE}
flickr_api_key = 'd4a3326bfa4bdbfaba49ab6bd8b40bab'
### plugin your credentials
options("googleAuthR.client_id" = "425021048557-km10oe85dmkt78rto0ttqs1uo2mp60hb.apps.googleusercontent.com")
options("googleAuthR.client_secret" = "6RxGH8lWDOLiNVFoxSKB12Cl")
```


```{r, query flickr,cache=TRUE}
#### set search parameters ####
# bbox='-64.114332,44.442498,-63.802948,44.705362'
bbox <- paste(st_bbox(st_transform(regions,"+proj=longlat +datum=WGS84")),collapse = ',')

#### download photo metadata ####
# sub_bbox <- splitbbox(flickr_api_key, bbox)
# writeLines(sub_bbox,"sub_bbox")
# sub_bbox <- readLines("sub_bbox")
# photos <- flickr.meta.dl(flickr_api_key, sub_bbox)
# write.csv(photos,"photos.csv",row.names = FALSE)

photos <- read.csv("photos.csv")
head(photos)
```


```{r, plot photos,cache=TRUE,eval=F}
photosbyocean <- st_as_sf(photos,
                 coords = c("longitude", "latitude"),
                 remove = FALSE,
                 crs="+proj=longlat +datum=WGS84") %>% 
  st_transform(st_crs(regions)) %>% 
  filter(lengths(st_covered_by(.,regions3kmbuff))>0)

save(photosbyocean,file="photosocean.Rdata")
```

```{r, plot photos by ocean}
load("photosbyocean.Rdata")

ylim <- sp::bbox(as(photosbyocean,"Spatial"))[c(2,4)]
xlim <- sp::bbox(as(photosbyocean,"Spatial"))[c(1,3)]

ggplot() +
  geom_sf(data=regions,aes(fill=Name))+ 
  geom_sf(data=photosbyocean[sample(1:nrow(photos),5000),])+ # only plotting 5000 points to save time, because that's enough to get the picture!
  coord_sf(xlim=xlim, ylim=ylim)
```


```{r, query google,cache=TRUE}
## use the fantastic Google Auth R package
### define scope!
options("googleAuthR.scopes.selected" = c("https://www.googleapis.com/auth/cloud-platform"))
googleAuthR::gar_auth()

pb <- txtProgressBar()
google <- rep(NA,nrow(photosbyocean))
if(file.exists("google.Rdata")) load("google.Rdata")
for(i in 1:nrow(photosbyocean)){
  if(is.na(google[i])){
    google[i] <- try(list(getGoogleVisionResponse(gsub("https","http",photosbyocean$url_m[i]))))
  }
  setTxtProgressBar(pb, i/nrow(photosbyocean))
  if(i%%1000==0) save(google,file="google.Rdata")
}
save(google,file="google.Rdata")
close(pb)

photosbyocean$google <- google

photosbyocean <- photosbyocean[lengths(photosbyocean$google)>1,] %>%
  data.frame() %>%
    unnest(google)
write.csv(photosbyocean,"photos_google.csv",row.names = FALSE)

photosbyocean <- read.csv("photos_google.csv")
head(photosbyocean)
```


```{r, identify ocean,cache=TRUE}
# sort(unique(photosbyocean$description))
oceanwords <- c("beach","boat","cape","coast","dock","harbor","headland","lighthouse","marina","ocean","sail","sailboat","sailing","sea","shore","water","wave")

oceanphotos <- photosbyocean %>%
  mutate(ocean=description %in% oceanwords) %>% 
  filter(ocean) %>% 
  select(-mid,-description,-score) %>%
  unique() %>% 
  st_as_sf(coords = c("longitude", "latitude"),
           remove = FALSE,
           crs="+proj=longlat +datum=WGS84") %>% 
  st_transform(st_crs(regions))

ggplot() +
  geom_sf(data=regions,aes(fill=Name))+
  geom_sf(data=oceanphotos)+
  coord_sf(xlim=xlim, ylim=ylim)
```

```{r, ocean photo heatmap,cache=TRUE}
bb <- sp::Spatial(sp::bbox(rgeos::gBuffer(as(oceanphotos,"Spatial"),width=10000)), proj4string = sp::CRS(st_crs(regions)$proj4string))
             
hexgrid <- sp::HexPoints2SpatialPolygons(sp::spsample(bb, type="hexagonal", n=100))

hexgrid <- hexgrid %>% 
  st_as_sf() %>% 
  mutate(oceanphoto=lengths(st_covers(.,oceanphotos)))

ggplot() +
  geom_sf(data=hexgrid,aes(fill=oceanphoto))+
  scale_fill_continuous(trans = "log")+
  geom_sf(data=regions,fill="transparent",aes(colour=Name))+
  geom_sf(data=oceanphotos)+
  coord_sf(xlim=xlim, ylim=ylim)


```

```{r, plot by census,cache=TRUE}
#### load census dissemination area shapefile ####
censusdissem <- read_sf("../Spatial/cencusdissem","gda_000b11a_e") %>% # keep only relevant shapefiles
  filter(PRNAME %in% c("New Brunswick / Nouveau-Brunswick",
                         "Quebec / Québec",
                         "Nova Scotia / Nouvelle-Écosse",
                         "Prince Edward Island / Île-du-Prince-Édouard",
                         "Newfoundland and Labrador / Terre-Neuve-et-Labrador")) %>% 
  st_transform(st_crs(regions)) %>% 
  filter(lengths(st_intersects(.,st_buffer(st_union(st_convex_hull(regions)),dist=3000)))>0) %>% #coarse filter
  filter(lengths(st_intersects(.,st_union(st_buffer(regions,dist=3000))))>0) %>%                 #fine filter
  mutate(DAUID = as.integer(as.character(DAUID))) # for the join with population below

ggplot() +
  geom_sf(data=regions,fill="transparent",aes(colour=Name))+
  geom_sf(data=censusdissem,aes(fill=censusdissem$CDNAME))+
  scale_fill_discrete(guide=FALSE)
```


```{r, plot population,cache=TRUE}
#### load relevant population files ####
pop <- rbind(read.csv("../Spatial//population/98-316-XWE2011001-1501-NB.csv", stringsAsFactors = FALSE),
             read.csv("../Spatial//population/98-316-XWE2011001-1501-QUE.csv", stringsAsFactors = FALSE),
             read.csv("../Spatial//population/98-316-XWE2011001-1501-NS.csv", stringsAsFactors = FALSE),
             read.csv("../Spatial//population/98-316-XWE2011001-1501-PEI.csv", stringsAsFactors = FALSE),
             read.csv("../Spatial//population/98-316-XWE2011001-1501-NL.csv", stringsAsFactors = FALSE))


pop <- pop %>% 
    filter(Topic=="Population and dwelling counts") %>%
    select(Geo_Code,Characteristic,Total) %>%
    spread(Characteristic,Total)

# join and count photos
censuspop <- left_join(censusdissem,pop,by=c("DAUID"="Geo_Code")) %>% 
  mutate(oceanphoto=lengths(st_covers(.,oceanphotos)),
         `Population density per square kilometre`=`Population in 2011`/`Land area (square km)`)

ggplot() +
  geom_sf(data=regions,fill="transparent",aes(colour=Name))+
  geom_sf(data=censuspop,colour='transparent',aes(fill=`Population density per square kilometre`))+
  scale_fill_continuous(trans = "log")

ggplot() +
  geom_sf(data=regions,fill="transparent",aes(colour=Name))+
  geom_sf(data=censuspop,colour='transparent',aes(fill=oceanphoto))+
  scale_fill_continuous(trans = "log")

```

